{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.1"
    },
    "colab": {
      "name": "Train.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BFPsEJ6mb3W3",
        "colab_type": "text"
      },
      "source": [
        "# Music Generation with LSTM Network : training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wixg-6qbb3XF",
        "colab_type": "text"
      },
      "source": [
        "I- Introduction\n",
        "--------\n",
        "Deep learning has always been a hard and challenging task for us, and probably for all data science students. This is due to the complexity of its network and the multitude of its hyperparameters that need to be tunned according to each case of study. However, its use is still attractive thanks to the promosing results that it shows on so many fields.\n",
        "\n",
        "In addition to traditional tasks such as prediction, classification and translation, deep learning is receiving growing attention as an approach for music generation\n",
        "\n",
        "This work describes an algorithmic approach to the generation of music based on LSTM model. The key goal is to model and learn musical notes, then generate new musical content.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cJXYqCbjb3XI",
        "colab_type": "text"
      },
      "source": [
        "II- Import necessary libraries\n",
        "------------\n",
        "* **Music21** is a Python toolkit that allows us to teach the fundamentals of music theory, generate music examples and study music. The purpose of using it here is to extract the contents of our dataset and to take the output of the neural network and translate it to musical notation.\n",
        "* **Keras** is a free open source Python library for developing and evaluating deep learning models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LtIxF5z_b3XN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pickle\n",
        "import numpy\n",
        "from music21 import converter, instrument, note, chord\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import LSTM\n",
        "from keras.layers import Activation\n",
        "from keras.layers import BatchNormalization as BatchNorm\n",
        "from keras.utils import np_utils\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from mido import MidiFile\n",
        "import os"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Ygxm_xrb3XY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_network():\n",
        "    \"\"\" Train a Neural Network to generate music \"\"\"\n",
        "    notes = get_notes()\n",
        "\n",
        "    # get amount of pitch names\n",
        "    n_vocab = len(set(notes))\n",
        "\n",
        "    network_input, network_output = prepare_sequences(notes, n_vocab)\n",
        "\n",
        "    model = create_network(network_input, n_vocab)\n",
        "\n",
        "    train(model, network_input, network_output)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3d-dq6RAb3Xp",
        "colab_type": "text"
      },
      "source": [
        "III- Data Preparation\n",
        "-----------\n",
        "\n",
        "We work with audios in MIDI format. The dataset we worked with is ***midi_songs***. It is composed from 99 audios of piano music"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MLz2BzV2b3YD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "midi_songs=os. listdir('midi_songs')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GtCS2QGsb3YY",
        "colab_type": "text"
      },
      "source": [
        "### Extract notes from the dataset\n",
        "\n",
        "The **get_notes()** function is used to convert the audio files into Music21 objects with the statment *converter.parse()*. Then it devides each parsed file to streams. Each stream represents a different isntrument\n",
        "\n",
        "Now the streams are prepared, we extract notes from them. Since we need just one instrument to extract notes we work just with one stream (parts[0]).\n",
        "\n",
        "Here the Music21 library needs to distinguish between pitches and chords in order to extract notes properly:\n",
        "\n",
        "* A Pitch (also called note) refers to the frequency of the sound, or how high or low it is and is represented with the letters [A, B, C, D, E, F, G], with A being the highest and G being the lowest.\n",
        "\n",
        "* A chord, in music, is any harmonic set of pitches consisting of multiple notes that are heard as if sounding simultaneously.\n",
        "\n",
        "By the end, we keep the notes extracted in a filepath."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bJgm1KPrb3Yb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_notes():\n",
        "    \"\"\" Get all the notes and chords from the midi files in the ./midi_songs directory \"\"\"\n",
        "    notes = []\n",
        "    \n",
        "    for file in midi_songs:\n",
        "        file = r'midi_songs/' + file\n",
        "        #midi = MidiFile(file, clip=True)\n",
        "        midi = converter.parse(file)\n",
        "\n",
        "        print(\"Parsing %s\" % file)\n",
        "\n",
        "        notes_to_parse = None\n",
        "\n",
        "        try: # file has instrument parts\n",
        "            s2 = instrument.partitionByInstrument(midi) # devide the audio streams by instruments\n",
        "            notes_to_parse = s2.parts[0].recurse() #devide every instrument stream to \"sub streams\" recursively\n",
        "        except: # file has notes in a flat structure\n",
        "            notes_to_parse = midi.flat.notes  # in case of  one instrument\n",
        "\n",
        "        for element in notes_to_parse:\n",
        "            if isinstance(element, note.Note): # collect notes names ex: B-2\n",
        "                notes.append(str(element.pitch))\n",
        "            elif isinstance(element, chord.Chord):  # collect chords (notes played simultaniously) ex: 8.0.11\n",
        "                notes.append('.'.join(str(n) for n in element.normalOrder))\n",
        "\n",
        "    with open('data/notes', 'wb') as filepath:\n",
        "        pickle.dump(notes, filepath)\n",
        "\n",
        "    return notes"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rZE--WNfb3Yt",
        "colab_type": "text"
      },
      "source": [
        "### Prepare sequences used by the Neural Network\n",
        " The function **prepare_sequences(notes, n_vocab)** allows us to create input sequences of the network and their corresponding outputs\n",
        " \n",
        " Here we have chosen to work with a sequence of length=100. That means that we will train our model in a way that it will be allowed to figure out the next appropriate note or chord based on the previous 100 notes / chords.\n",
        " \n",
        " First, we create a dictionary called *note_to_int*. It contains the sorted notes generated from the audios. We provide each note/chord with an index in order to work with integers (the index of the notes) instead of chatarcters (aka the notes) as inputs of the LSTM network\n",
        " \n",
        " The variable *network_input* is a list that contains sub-lists. Each one represents a sequence (100 indexes referring to notes). And the variable *network_output* is a list of the indexes of notes corresponding to every sequence in the network_input\n",
        " \n",
        "*n_patterns* corresponds to the number of sequences that will be introduced to the LSTM model\n",
        " \n",
        " It is more efficient to normalize the data before training any neural network because it speeds up learning and lead to faster convergence. To do so, network_input was devided by the number of the notes (n_vocabs)\n",
        "\n",
        " Now that the list of sequences is prepared, the last step is to reshape it into a format that is compatible with LSTM network. *The input_shape* argument in the network takes besides the batch size two arguments, the time step and the number of input units. The time step reffers to how many points (here notes) are in the sequence. The number of input units is the number of sequences, here called n_patterns\n",
        " \n",
        " The network_output is converted to zeros vectors with 1 in the the index referring to the note by the **np_utils.to_categorical()** function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iuI_HFIMb3Y3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def prepare_sequences(notes, n_vocab):\n",
        "    \"\"\" Prepare the sequences used by the Neural Network \"\"\"\n",
        "    sequence_length = 100\n",
        "\n",
        "    # get all pitch names\n",
        "    pitchnames = sorted(set(item for item in notes)) # list of unrepeated notes  organised by lexical order\n",
        "\n",
        "     # create a dictionary to map pitches to integers\n",
        "    note_to_int = dict((note, number) for number, note in enumerate(pitchnames)) # dictionary of pitchnames indexed\n",
        "\n",
        "    network_input = []\n",
        "    network_output = []\n",
        "\n",
        "    # create input sequences and the corresponding outputs\n",
        "    for i in range(0, len(notes) - sequence_length, 1):\n",
        "        sequence_in = notes[i:i + sequence_length]\n",
        "        sequence_out = notes[i + sequence_length]\n",
        "        network_input.append([note_to_int[char] for char in sequence_in])\n",
        "        network_output.append(note_to_int[sequence_out])\n",
        "\n",
        "    n_patterns = len(network_input)\n",
        "\n",
        "    # reshape the input into a format compatible with LSTM layers\n",
        "    network_input = numpy.reshape(network_input, (n_patterns, sequence_length, 1))\n",
        "    # normalize input\n",
        "    network_input = network_input / float(n_vocab)\n",
        "\n",
        "    network_output = np_utils.to_categorical(network_output) #convert output notes to zeros vectors with 1 in the the index referring to the note\n",
        "\n",
        "    return (network_input, network_output)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XsH-PABQb3ZJ",
        "colab_type": "text"
      },
      "source": [
        "VI- Create the LSTM Neural Network\n",
        "------\n",
        "### Why LSTM?\n",
        "Long short-term memory (LSTM) is an artificial recurrent neural network (RNN) architecture used in deep learning.  It has feedback connections that can  process sequences of data instead of one single data points. LSTMs were created in order to manage the exploding and vanishing gradient problems caused while using traditional RNNs. \n",
        "\n",
        "This type of neural networks gives the best results when it comes to sequential data such as time series and texts. Since musical notes can be seen as long-term patterns where historical information matters, LSTM networks will be extremly useful in our situation\n",
        "\n",
        "### Network Architecture\n",
        "* Here the network trained is composed of two LSTM layers with 512 neurons for each one.\n",
        "* In order to avoid overfitting, two dropout layers are used. \n",
        "* And since data values are adjusted with weights and parameters of the network, making them too big or too small, by adding batch normalization layers, this issue is largely avoided.\n",
        "* Each dense (fully connected) layer is followed by an activation function. RELU is used in the hidden layer and SOFTMAX is used so that the model gives by the end the probalility of appearance of each single note\n",
        "* rmsprop optimizer is heavily used with LSTM network. It helps to deal with the problems of exploding and vanishing gradient because it uses a moving average of squared gradients to normalize the gradient itself. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sU1mA-JMb3ZL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_network(network_input, n_vocab):\n",
        "    \"\"\" create the structure of the neural network \"\"\"\n",
        "    model = Sequential()\n",
        "    model.add(LSTM(\n",
        "        512,\n",
        "        input_shape=(network_input.shape[1], network_input.shape[2]),\n",
        "        recurrent_dropout=0.3,\n",
        "        return_sequences=True\n",
        "    ))\n",
        "    model.add(LSTM(512, return_sequences=True, recurrent_dropout=0.3,))\n",
        "    model.add(LSTM(512))\n",
        "    model.add(BatchNorm())\n",
        "    model.add(Dropout(0.3))\n",
        "    model.add(Dense(256))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(BatchNorm())\n",
        "    model.add(Dropout(0.3))\n",
        "    model.add(Dense(n_vocab))\n",
        "    model.add(Activation('softmax'))\n",
        "    model.compile(loss='categorical_crossentropy', optimizer='rmsprop')\n",
        "\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k3vIZ8VCb3ZX",
        "colab_type": "text"
      },
      "source": [
        "### Fitting the model\n",
        "The **train()** function is called to fit the network with the data already prepared (network_input and network_output). Here we trained the model with *100 epochs and batches of size 64*\n",
        "\n",
        "For every epoch, the weights of the network are collected and saved"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I1EGti7nb3ZZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(model, network_input, network_output):\n",
        "    \"\"\" train the neural network \"\"\"\n",
        "    filepath = \"weights-improvement-{epoch:02d}-{loss:.4f}-bigger.hdf5\"\n",
        "    checkpoint = ModelCheckpoint(\n",
        "        filepath,\n",
        "        monitor='loss',\n",
        "        verbose=0,\n",
        "        save_best_only=True,\n",
        "        mode='min'\n",
        "    )\n",
        "    callbacks_list = [checkpoint]\n",
        "\n",
        "    model.fit(network_input, network_output, epochs=100, batch_size=64, callbacks=callbacks_list)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "Bn05W4LSb3Zk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if __name__ == '__main__':\n",
        "    train_network()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}