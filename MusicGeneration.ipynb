{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.1"
    },
    "colab": {
      "name": "Music.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qvxoENzc7z_8",
        "colab_type": "text"
      },
      "source": [
        "# Music generation with LSTM Network: generation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jRSssiFXccKD",
        "colab_type": "text"
      },
      "source": [
        "In this part, we are trying to generate new music tracks from the model trained. The generation process includes some steps already explained in the training part. These steps are the mostly related to the data preparation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ktPpNSlzdLZ4",
        "colab_type": "text"
      },
      "source": [
        "## I- Import the necessary libraries:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "6Fm03-y17doH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\" This module generates notes for a midi file using the\n",
        "    trained neural network \"\"\"\n",
        "import pickle\n",
        "import numpy\n",
        "from music21 import instrument, note, stream, chord\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import LSTM\n",
        "from keras.layers import BatchNormalization as BatchNorm\n",
        "from keras.layers import Activation\n",
        "from keras.models import load_model\n",
        "import keras"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NmrAJr2-dSqW",
        "colab_type": "text"
      },
      "source": [
        "## II- Data preparation:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ciAxUUeB9HxI",
        "colab_type": "text"
      },
      "source": [
        "The process of preparing sequences is the same as in the training part. We introduce the notes, which can be the ones on which we trained the model if we want output with the same notes' dictionary. However, if we want to generate music from a specific set of notes in some tracks, we can introduce some new midi files and prepare a new dictionary. The sequence length used in here is 100.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hc_s0OeX9C4G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def prepare_sequences(notes, pitchnames, n_vocab):\n",
        "    \"\"\" Prepare the sequences used by the Neural Network \"\"\"\n",
        "    # map between notes and integers and back\n",
        "    note_to_int = dict((note, number) for number, note in enumerate(pitchnames))\n",
        "\n",
        "    sequence_length = 100\n",
        "    network_input = []\n",
        "    output = []\n",
        "    for i in range(0, len(notes) - sequence_length, 1):\n",
        "        sequence_in = notes[i:i + sequence_length]\n",
        "        sequence_out = notes[i + sequence_length]\n",
        "        network_input.append([note_to_int[char] for char in sequence_in])\n",
        "        output.append(note_to_int[sequence_out])\n",
        "\n",
        "    n_patterns = len(network_input)\n",
        "\n",
        "    # reshape the input into a format compatible with LSTM layers\n",
        "    normalized_input = numpy.reshape(network_input, (n_patterns, sequence_length, 1))\n",
        "    # normalize input\n",
        "    normalized_input = normalized_input / float(n_vocab)\n",
        "\n",
        "    return (network_input, normalized_input)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YUgDQA9WeMi4",
        "colab_type": "text"
      },
      "source": [
        "## III- Newtwork preparation:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2mLhYl6AeXx3",
        "colab_type": "text"
      },
      "source": [
        "Training LSTM deep learning models is computationally intensive. For instance, Training the model we use for prediction on the kaggle platform with a 16 Go GPU took 9 hours to train a model on 62 epochs. Therefore, we prepare a model with the same structure (same layers and number of neurons), and upload the weigths which we saved in the training part."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "16ytcxG0eIIA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_network(network_input, n_vocab):\n",
        "    \"\"\" create the structure of the neural network \"\"\"\n",
        "    model = Sequential()\n",
        "    model.add(LSTM(\n",
        "        512,\n",
        "        input_shape=(network_input.shape[1], network_input.shape[2]),\n",
        "        recurrent_dropout=0.3,\n",
        "        return_sequences=True\n",
        "    ))\n",
        "    model.add(LSTM(512, return_sequences=True, recurrent_dropout=0.3,))\n",
        "    model.add(LSTM(512))\n",
        "    model.add(BatchNorm())\n",
        "    model.add(Dropout(0.3))\n",
        "    model.add(Dense(256))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(BatchNorm())\n",
        "    model.add(Dropout(0.3))\n",
        "    model.add(Dense(n_vocab))\n",
        "    model.add(Activation('softmax'))\n",
        "    model.compile(loss='categorical_crossentropy', optimizer='rmsprop')\n",
        "\n",
        "    # Load the weights to each node\n",
        "    model.load_weights('../input/weights/weights-improvement-62-1.0400-bigger.hdf5')\n",
        "\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yhgyzfxPfCBB",
        "colab_type": "text"
      },
      "source": [
        "## IV- Notes generation:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P4HKnGomfHZd",
        "colab_type": "text"
      },
      "source": [
        "The process of notes generation is based on predicting the most probable next note from the dictionary. \n",
        "\n",
        "In fact, the generation function predicts a 500 sequence of notes. The first step is to take a random starting point from the notes' dictionary introduced. After that, we predict one note at a time.\n",
        "\n",
        "The prediction takes the argmax of probabilities between the possible outputs, which means the class (ie the note) with the highest probability. \n",
        "\n",
        "Each time, the note is added to the ones we already predicted and the sequence we introduce for the next prediction is updated to introduce the latest note we got. At the end, we have a list with 500 notes generated."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bfW7CqL9fBFJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generate_notes(model, network_input, pitchnames, n_vocab):\n",
        "    \"\"\" Generate notes from the neural network based on a sequence of notes \"\"\"\n",
        "    # pick a random sequence from the input as a starting point for the prediction\n",
        "    start = numpy.random.randint(0, len(network_input)-1)\n",
        "\n",
        "    int_to_note = dict((number, note) for number, note in enumerate(pitchnames))\n",
        "\n",
        "    pattern = network_input[start]\n",
        "    prediction_output = []\n",
        "\n",
        "    # generate 500 notes\n",
        "    for note_index in range(500):\n",
        "        prediction_input = numpy.reshape(pattern, (1, len(pattern), 1))\n",
        "        prediction_input = prediction_input / float(n_vocab)\n",
        "\n",
        "        prediction = model.predict(prediction_input, verbose=0)\n",
        "\n",
        "        index = numpy.argmax(prediction)\n",
        "        result = int_to_note[index]\n",
        "        prediction_output.append(result)\n",
        "\n",
        "        pattern.append(index)\n",
        "        pattern = pattern[1:len(pattern)]\n",
        "\n",
        "    return prediction_output\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Bra0_EPi4Sz",
        "colab_type": "text"
      },
      "source": [
        "## V- Audio file creation:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BLb-HyA-i-NR",
        "colab_type": "text"
      },
      "source": [
        "We get the notes predicted from the function generate_notes, the output is a list containing chords and notes in the form of a string. So, in order to transfrorm our prediction output to an audio file, we use the functions that are already built in the music21 library.\n",
        "\n",
        "The issue in this part that is encountered is to generate notes with instruments other than the Piano. According to the documentation of the library, the use of the [instrument.\"Name of the instrument\"] function determines on which instrument the notes are generated. However, when we tried to generate notes with instruments other than piano, for instance AcousticGuitar, Clarinet, Drums..., the output is always piano notes.\n",
        "\n",
        "After generating the notes one by one, and seperating them with an offset of 0.5, we use the function .Stream to put all the output in an audio file that we save in a midi file."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GGz7s0yOi3Q-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_midi(prediction_output):\n",
        "    \"\"\" convert the output from the prediction to notes and create a midi file\n",
        "        from the notes \"\"\"\n",
        "    offset = 0\n",
        "    output_notes = []\n",
        "\n",
        "    # create note and chord objects based on the values generated by the model\n",
        "    for pattern in prediction_output:\n",
        "        # pattern is a chord\n",
        "        if ('.' in pattern) or pattern.isdigit():\n",
        "            notes_in_chord = pattern.split('.')\n",
        "            notes = []\n",
        "            for current_note in notes_in_chord:\n",
        "                new_note = note.Note(int(current_note))\n",
        "                new_note.storedInstrument = instrument.Piano()\n",
        "                notes.append(new_note)\n",
        "                new_chord = chord.Chord(notes)\n",
        "                new_chord.offset = offset\n",
        "                output_notes.append(new_chord)\n",
        "        # pattern is a note\n",
        "        else:\n",
        "            new_note = note.Note(pattern)\n",
        "            new_note.offset = offset\n",
        "            new_note.storedInstrument = instrument.Piano()\n",
        "           # new_note1 = note.Note(pattern)\n",
        "           # new_note1.offset = offset\n",
        "            #new_note1.storedInstrument = instrument.Clarinet\n",
        "            output_notes.append(new_note)\n",
        "            #output_notes.append(new_note1)\n",
        "\n",
        "        # increase offset each iteration so that notes do not stack\n",
        "        offset += 0.5\n",
        "\n",
        "    midi_stream = stream.Stream(output_notes)\n",
        "\n",
        "    midi_stream.write('midi', fp='test_output_dru.mid')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q-cXsnldl1TT",
        "colab_type": "text"
      },
      "source": [
        "This function is used to group all the functions presented above."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "qM7bWtEH7doT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def generate():\n",
        "    \"\"\" Generate a piano midi file \"\"\"\n",
        "    #load the notes used to train the model\n",
        "    with open('../input/notesmusic/fnotes_instruments', 'rb') as filepath:\n",
        "        notes = pickle.load(filepath)\n",
        "        notes = notes[5][1:]   #guitar notes\n",
        "        notes.append('0.1.1')\n",
        "    # Get all pitch names\n",
        "    pitchnames = sorted(set(item for item in notes))\n",
        "    # Get all pitch names\n",
        "    n_vocab = len(set(notes))\n",
        "\n",
        "    network_input, normalized_input = prepare_sequences(notes, pitchnames, n_vocab)\n",
        "    #model = load_model('weights-02-4.7661-dataall.hdf5')\n",
        "   # model = load_model('weights-02-4.7661-dataall.hdf5', custom_objects={\n",
        "    #'Adam': lambda **kwargs: hvd.DistributedOptimizer(keras.optimizers.Adam(**kwargs))})\n",
        "    model = create_network(normalized_input, n_vocab)\n",
        "    prediction_output = generate_notes(model, network_input, pitchnames, n_vocab)\n",
        "    create_midi(prediction_output)\n",
        "\n",
        "\n",
        "\n",
        "                \n",
        "        \n",
        "        \n",
        "        \n",
        "        "
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}